{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib as plot \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('datafiles/train.dat', sep = ' ', header = 0)\n",
    "\n",
    "# all indices in the training set \n",
    "index = train.index\n",
    "\n",
    "# split the training set indices into training and validation set indices \n",
    "training_indices, val_indices = train_test_split(index, test_size = 0.1, random_state = 42)\n",
    "\n",
    "# write validation indices to a text file for static evaluation \n",
    "val_indices_list = val_indices.tolist()\n",
    "\n",
    "# go through the training data and place each of the corresponding ratings for the validation set into a separate list \n",
    "val_ratings = [] \n",
    "for index in val_indices: \n",
    "    rating = train.loc[index, 'rating']\n",
    "    val_ratings.append(rating) \n",
    "\n",
    "# matrix of users and their movie ratings - will be very sparse \n",
    "# each row is a user ID, each column is a movie ID \n",
    "rating_matrix = train.pivot_table(index = 'userID', columns = 'movieID', values = 'rating', fill_value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean square error function \n",
    "def rmse(predictions, real): \n",
    "    errors = (np.array(predictions) - np.array(real)) ** 2\n",
    "    mse = np.mean(errors)\n",
    "    rmse = np.sqrt(mse) \n",
    "    return rmse \n",
    "\n",
    "def movie_average_rating(movieID):\n",
    "    ratings = train[train['movieID'] == movieID]\n",
    "    average = ratings['rating'].mean() \n",
    "    return average\n",
    "\n",
    "def user_average_rating(userID):\n",
    "    ratings = train[train['userID'] == userID]\n",
    "    average = ratings['rating'].mean() \n",
    "    return average \n",
    "\n",
    "def global_average_rating():\n",
    "    index = train.index\n",
    "    ratings = []\n",
    "    for idx in index: \n",
    "        rating = train.loc[idx, 'rating']\n",
    "        ratings.append(rating) \n",
    "\n",
    "    average = sum(ratings) / len(ratings)\n",
    "    return average \n",
    "\n",
    "def jaccard(x, y): \n",
    "    intersection = np.sum(np.minimum(x, y))\n",
    "    union = np.sum(np.maximum(x, y))\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures for user similarity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix of cosine similarities between each user to every other user \n",
    "# each row is a user ID, each column is a user ID \n",
    "\n",
    "# cosine similarity \n",
    "similarity_matrix = pd.DataFrame(cosine_similarity(rating_matrix),index = rating_matrix.index, columns = rating_matrix.index)\n",
    "\n",
    "# Pearson correlation coefficient \n",
    "# similarity_matrix = pd.DataFrame(1 - pairwise_distances(rating_matrix, metric = 'correlation'),index = rating_matrix.index, columns = rating_matrix.index)\n",
    "\n",
    "# Jaccard similarity measure \n",
    "# similarity_matrix = pd.DataFrame(1 - pairwise_distances(rating_matrix, metric = jaccard), index = rating_matrix.index, columns = rating_matrix.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation using Collaborative Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864958308345157\n"
     ]
    }
   ],
   "source": [
    "val_predictions = []\n",
    "\n",
    "# iterate through the rows in the validation set \n",
    "for index in val_indices: \n",
    "    # get the user and the movie for which we need to predict the rating \n",
    "    user_id = train.loc[index, 'userID']\n",
    "    movie_id = train.loc[index, 'movieID']\n",
    "\n",
    "    # some movies in the test set aren't in the training set so we handle that here \n",
    "    # if movie_id not in rating_matrix.columns: \n",
    "    #     avg = movie_average_rating(movie_id)\n",
    "    #     val_predictions.append(avg)\n",
    "    #     continue\n",
    "\n",
    "    if movie_id not in rating_matrix.columns: \n",
    "        average = user_average_rating(user_id)\n",
    "        val_predictions.append(round(average, 1))\n",
    "        continue\n",
    "\n",
    "    # if movie_id not in rating_matrix.columns: \n",
    "    #     average = global_average_rating() \n",
    "    #     val_predictions.append(round(average, 1))\n",
    "    #     continue\n",
    "\n",
    "    # get the ratings that this user made \n",
    "    target_user_ratings = rating_matrix.loc[user_id]\n",
    "\n",
    "    # get the movie IDs of those ratings \n",
    "    target_user_rated_movies = target_user_ratings[target_user_ratings != 0].index\n",
    "\n",
    "    # get the similar users and sort from most similar to least \n",
    "    similar_users = similarity_matrix.loc[user_id].sort_values(ascending = False).index\n",
    "\n",
    "    # array of the top most similar users to the target user \n",
    "    top_k_similar = [] \n",
    "    count = 0 \n",
    "    # get the k most similar users that rated this movie \n",
    "    # if they didn't rate this movie, skip them \n",
    "    for user in similar_users: \n",
    "        if count >= 20: \n",
    "            break \n",
    "\n",
    "        if rating_matrix.loc[user, movie_id] != 0 and user != user_id:\n",
    "            top_k_similar.append(user) \n",
    "            count += 1\n",
    "    \n",
    "    # get the average of the ratings for this movie from the 3 most similar users \n",
    "    rating = round(rating_matrix.loc[top_k_similar, movie_id].mean(), 1)\n",
    "\n",
    "    # this is incase none of the other users rated this movie so all we can do is just use the user's actual rating \n",
    "    if(len(top_k_similar) == 0): \n",
    "        rating = rating_matrix.loc[user_id, movie_id]\n",
    "\n",
    "    val_predictions.append(rating)\n",
    "\n",
    "error = rmse(np.array(val_predictions), np.array(val_ratings)) \n",
    "print(error) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation using Global Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_avg = global_average_rating() \n",
    "\n",
    "val_predictions = []\n",
    "\n",
    "# iterate through the rows in the validation set \n",
    "for index in val_indices: \n",
    "    # get the user and the movie for which we need to predict the rating \n",
    "    user_id = train.loc[index, 'userID']\n",
    "    movie_id = train.loc[index, 'movieID']\n",
    "\n",
    "    if movie_id not in rating_matrix.columns: \n",
    "        average = user_average_rating(user_id)\n",
    "        val_predictions.append(round(average, 1))\n",
    "        continue\n",
    "\n",
    "    movie_avg = movie_average_rating(movie_id) \n",
    "\n",
    "    # difference between the global average and the movie's average rating \n",
    "    movie_mean_diff = global_avg - movie_avg \n",
    "\n",
    "    user_avg = user_average_rating(user_id) \n",
    "\n",
    "    # difference between the global average and the user's average rating \n",
    "    user_mean_diff = global_avg - user_avg \n",
    "\n",
    "    rating = movie_avg + movie_mean_diff + user_mean_diff \n",
    "\n",
    "    val_predictions.append(rating)\n",
    "\n",
    "error = rmse(np.array(val_predictions), np.array(val_ratings)) \n",
    "print(error) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the test set without ground truth ratings \n",
    "test = pd.read_csv('datafiles/test.dat', sep = ' ', header = 0)\n",
    "\n",
    "predictions = [] \n",
    "\n",
    "for index, row in test.iterrows(): \n",
    "    user_id = row['userID']\n",
    "    movie_id = row['movieID']\n",
    "\n",
    "    if movie_id not in rating_matrix.columns: \n",
    "        average = user_average_rating(user_id)\n",
    "        predictions.append(round(average, 1))\n",
    "        continue\n",
    "\n",
    "    target_user_ratings = rating_matrix.loc[user_id]\n",
    "    target_user_rated_movies = target_user_ratings[target_user_ratings != 0].index\n",
    "    similar_users = similarity_matrix.loc[user_id].sort_values(ascending = False).index\n",
    "    top_k_similar = [] \n",
    "    count = 0 \n",
    "\n",
    "    for user in similar_users: \n",
    "        if count >= 20: \n",
    "            break \n",
    "\n",
    "        if rating_matrix.loc[user, movie_id] != 0 and user != user_id:\n",
    "            top_k_similar.append(user) \n",
    "            count += 1\n",
    "\n",
    "    rating = round(rating_matrix.loc[top_k_similar, movie_id].mean(), 1)\n",
    "    predictions.append(rating)\n",
    "\n",
    "with open(\"predictions.txt\", 'w') as file: \n",
    "    for prediction in predictions: \n",
    "        file.write(str(prediction) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
